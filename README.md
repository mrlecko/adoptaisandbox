# CSV Analyst Chat

An LLM-powered chat interface for analyzing CSV datasets with sandboxed SQL execution.

## Overview

CSV Analyst Chat enables natural language querying of CSV datasets through an intelligent agent that:
- Generates structured query plans (JSON DSL) or SQL from user questions
- Validates and compiles queries safely
- Executes queries in isolated sandboxed environments (Docker or Kubernetes)
- Returns results with full execution transparency and audit trails

**Key Features:**
- ðŸ¤– LangChain-powered conversational agent
- ðŸ”’ Sandboxed execution with strict security controls
- ðŸ“Š Multiple curated datasets with example prompts
- ðŸŽ¯ Structured query planning with deterministic SQL compilation
- ðŸ” Full execution transparency (query plans, SQL, logs, metadata)
- â˜¸ï¸ Kubernetes-ready with Helm charts for production deployment

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚     UI      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Server      â”‚
â”‚  (FastAPI + Agent)  â”‚
â”‚  - Dataset APIs     â”‚
â”‚  - Chat endpoint    â”‚
â”‚  - Run orchestrationâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Executor API
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Executor Layer    â”‚â”€â”€â”€â”€â”€>â”‚  Sandboxed       â”‚
â”‚  - DockerExecutor   â”‚      â”‚  SQL Runner      â”‚
â”‚  - K8sJobExecutor   â”‚      â”‚  (DuckDB)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Components:**
- **UI**: Chat interface (LangChain Agent UI starter)
- **Agent Server**: FastAPI backend with LangChain agent
- **Runner**: Isolated SQL execution environment (DuckDB in Docker/K8s)
- **Datasets**: Versioned CSV datasets with metadata

## Quick Start (Local Development)

### Prerequisites
- Docker and Docker Compose
- Python 3.11+
- Node.js 18+ (for UI)
- Make

### Run Locally

```bash
# Start all services
make dev

# Access the UI
open http://localhost:3000
```

Try these example prompts:
- "Show me top 10 orders by total amount"
- "What's the average CSAT score by ticket priority?"
- "Which sensors had anomalies in the last 24 hours?"

### Development Setup

```bash
# Install Python dependencies (agent server)
cd agent-server
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Install UI dependencies
cd ui
npm install

# Run tests
make test

# Run security tests
make test-security
```

## Quick Start (Kubernetes)

### Prerequisites
- kubectl
- Helm 3
- A Kubernetes cluster (kind, k3d, or cloud provider)

### Deploy to Kubernetes

```bash
# Create local cluster (optional)
make k8s-up

# Install via Helm
make helm-install

# Test deployment
make k8s-smoke

# Access the application
kubectl port-forward svc/csv-analyst-ui 3000:80
```

## Project Structure

```
.
â”œâ”€â”€ agent-server/       # FastAPI backend + LangChain agent
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agent/      # Agent graph and tools
â”‚   â”‚   â”œâ”€â”€ executors/  # Docker/K8s execution backends
â”‚   â”‚   â”œâ”€â”€ models/     # Pydantic models (QueryPlan, etc.)
â”‚   â”‚   â””â”€â”€ validators/ # SQL and plan validation
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ datasets/           # CSV datasets and metadata
â”‚   â”œâ”€â”€ registry.json   # Dataset catalog
â”‚   â”œâ”€â”€ ecommerce/      # Dataset A
â”‚   â”œâ”€â”€ support/        # Dataset B
â”‚   â””â”€â”€ sensors/        # Dataset C
â”œâ”€â”€ runner/             # Sandboxed SQL execution
â”‚   â”œâ”€â”€ runner.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ ui/                 # Frontend (LangChain Agent UI)
â”œâ”€â”€ helm/               # Kubernetes Helm charts
â”‚   â””â”€â”€ csv-analyst-chat/
â”œâ”€â”€ tests/              # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ security/
â”œâ”€â”€ docs/               # Documentation and PRDs
â”œâ”€â”€ .github/            # CI/CD workflows
â”œâ”€â”€ Makefile            # Common tasks
â””â”€â”€ README.md
```

## Security Model

CSV Analyst Chat implements defense-in-depth security:

1. **SQL Validation**
   - Denylist for dangerous operations (DROP, DELETE, INSERT, etc.)
   - Allowlist mode for SELECT queries only
   - Query plan validation before compilation

2. **Sandboxed Execution**
   - Network isolation (`--network none` in Docker)
   - Read-only root filesystem
   - Resource limits (CPU, memory, PIDs)
   - Non-root user execution
   - Temporary filesystem restrictions

3. **Kubernetes Security**
   - Pod Security Standards
   - Network policies (deny egress)
   - RBAC with minimal permissions
   - Security contexts enforced

4. **Output Controls**
   - Row limits (default 200)
   - Output size limits (64KB)
   - Data exfiltration heuristics

## Configuration

Key environment variables:

```bash
# Agent Server
ANTHROPIC_API_KEY=sk-ant-xxx    # Required
EXECUTION_MODE=docker           # docker or k8s
RUNNER_TIMEOUT=10               # Query timeout (seconds)
RUNNER_MAX_ROWS=200             # Max rows returned
LOG_LEVEL=info

# Kubernetes Mode
K8S_NAMESPACE=default
RUNNER_IMAGE=ghcr.io/user/csv-analyst-runner:latest
```

See `helm/csv-analyst-chat/values.yaml` for full configuration options.

## Development

### Adding a Dataset

1. Create a directory in `datasets/<dataset-name>/`
2. Add CSV files
3. Update `datasets/registry.json` with metadata
4. Add 4-6 example prompts
5. Run dataset validation: `make validate-datasets`

### Running Tests

```bash
# All tests
make test

# Unit tests only
make test-unit

# Integration tests
make test-integration

# Security tests (red team)
make test-security

# Coverage report
make coverage
```

### CI/CD

GitHub Actions automatically:
- Run tests on PRs
- Build Docker images
- Push to GHCR on main branch
- Tag releases with semantic versioning

## Deployment

See [docs/hosting.md](docs/hosting.md) for detailed deployment guides:
- Local development (Docker Compose)
- Local Kubernetes (kind/k3d)
- Cloud Kubernetes (GKE, EKS, AKS)
- Bare metal k3s

## Troubleshooting

**Common Issues:**

1. **Runner timeout**
   - Increase `RUNNER_TIMEOUT` in config
   - Check query complexity

2. **RBAC permission denied (K8s)**
   - Verify ServiceAccount has Job creation permissions
   - Check namespace matches

3. **Dataset not loading**
   - Verify `datasets/registry.json` syntax
   - Check file paths are correct

See [docs/troubleshooting.md](docs/troubleshooting.md) for more.

## Roadmap

**MVP (Current)**
- [x] Core agent with JSON query DSL
- [x] SQL validation and sandboxing
- [x] Docker and K8s execution modes
- [x] 3 curated datasets
- [ ] Production hosting
- [ ] CI/CD pipeline

**Stretch Goals**
- [ ] Restricted Python execution mode
- [ ] Chart visualization
- [ ] Query caching
- [ ] Multi-turn analysis sessions
- [ ] More datasets

## Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## License

MIT License - see [LICENSE](LICENSE) for details.

## Acknowledgments

Built with:
- [LangChain](https://langchain.com) - Agent framework
- [DuckDB](https://duckdb.org) - Embedded SQL engine
- [FastAPI](https://fastapi.tiangolo.com) - Backend framework
- [LangChain Agent UI](https://github.com/langchain-ai/agent-ui) - Frontend starter

---

**Status:** ðŸš§ Active Development

For questions or issues, please open a GitHub issue.
